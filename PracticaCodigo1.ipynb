{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamiento de Datos con Pandas, Numpy y Matplotlib\n",
    "## 1. Exploraci贸n del DataFrame\n",
    "Creamos un dataset simulando un registro de conexiones de red, este se lo almacena en un DataFrame. Exploramos las primeras filas, la informaci贸n general del DataFrame y las estad铆sticas descriptivas.\n",
    "\n",
    "En este bloque primero importamos las librer铆as/dependencias (pandas, numpy, matplotlib) que utilizaremos para el ejercicio.\n",
    "Luego pasamos a crear el datset \"data\" e incluir la informaci贸n que se llenara en 茅ste, p. ej.: fecha y hora, las ip origen  destino, el puerto, protocolo, los bytes que se han enviado y si la conexi贸n fue exitosa (true) o no (false).\n",
    "\n",
    "Una vez se ha llenado el dataset, usamos pandas para crear un DataFrame \"df\" a partir de este dataset.\n",
    "Luego mediante el uso de las bondades de pandas exploramos el DataFrame, vemos su informaci贸n y estad铆sticas.\n",
    "- df.head().- Muestra las 5 primeras filas del Data Frame,  esto permite revisar los primeros datos en el DataFrame para verificar que se hayan cargado correctamente.\n",
    "- df.info().- Este comando muestra la informaci贸n concisa del DataFrame, incluye: n煤mero de filas y columnas, nombres de las columnas, cantidad de valores nulos de cada columna, cuanta memoria usa el DataFrame,\n",
    "- df.describe().- Genera estad铆sticas descriptivas de las columnas num茅ricas del DataFrame, incluye informaci贸n como: \n",
    "    * el n煤mero de valores no nulos (count),\n",
    "    * la media de los valores (mean)\n",
    "    * la desviaci贸n est谩ndar (std),\n",
    "    * el valor m铆nimo (min),\n",
    "    * el primer cuartil (25%),\n",
    "    * la mediana (50%),\n",
    "    * el tercer cuartil (75%),\n",
    "    * y el valor m谩ximo (max).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Explorando el DataFrame:\n",
      "            timestamp    ip_origen ip_destino  puerto protocolo  \\\n",
      "0 2023-01-01 00:00:00  192.168.1.1   10.0.0.1      80      HTTP   \n",
      "1 2023-01-01 01:00:00  192.168.1.2   10.0.0.2     443     HTTPS   \n",
      "2 2023-01-01 02:00:00  192.168.1.3   10.0.0.3      22       SSH   \n",
      "3 2023-01-01 03:00:00  192.168.1.4   10.0.0.1    3389       RDP   \n",
      "4 2023-01-01 04:00:00  192.168.1.5   10.0.0.2    8080      HTTP   \n",
      "\n",
      "   bytes_enviados  exito_conexion  \n",
      "0            2875            True  \n",
      "1            3344            True  \n",
      "2            9272           False  \n",
      "3            5383            True  \n",
      "4            6365            True  \n",
      "\n",
      "Informaci贸n del DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   timestamp       10 non-null     datetime64[ns]\n",
      " 1   ip_origen       10 non-null     object        \n",
      " 2   ip_destino      10 non-null     object        \n",
      " 3   puerto          10 non-null     int64         \n",
      " 4   protocolo       10 non-null     object        \n",
      " 5   bytes_enviados  10 non-null     int64         \n",
      " 6   exito_conexion  10 non-null     bool          \n",
      "dtypes: bool(1), datetime64[ns](1), int64(2), object(3)\n",
      "memory usage: 622.0+ bytes\n",
      "None\n",
      "\n",
      "Estad铆sticas descriptivas:\n",
      "                 timestamp       puerto  bytes_enviados\n",
      "count                   10    10.000000       10.000000\n",
      "mean   2023-01-01 04:30:00  2402.800000     5240.600000\n",
      "min    2023-01-01 00:00:00    22.000000      411.000000\n",
      "25%    2023-01-01 02:15:00    80.000000     3120.500000\n",
      "50%    2023-01-01 04:30:00   443.000000     5142.000000\n",
      "75%    2023-01-01 06:45:00  3389.000000     7677.500000\n",
      "max    2023-01-01 09:00:00  8080.000000     9272.000000\n",
      "std                    NaN  3269.645404     2890.111001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6229/2243821585.py:6: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  'timestamp': pd.date_range(start='2023-01-01', periods=10, freq='H'),\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Creamos un dataset simulando un registro de conexiones de red\n",
    "data = {\n",
    "    'timestamp': pd.date_range(start='2023-01-01', periods=10, freq='H'),\n",
    "    'ip_origen': ['192.168.1.' + str(i) for i in range(1, 11)],\n",
    "    'ip_destino': ['10.0.0.' + str(i % 3 + 1) for i in range(10)],\n",
    "    'puerto': [80, 443, 22, 3389, 8080, 80, 443, 22, 8080, 3389],\n",
    "    'protocolo': ['HTTP', 'HTTPS', 'SSH', 'RDP', 'HTTP', 'HTTP', 'HTTPS', 'SSH', 'HTTP', 'RDP'],\n",
    "    'bytes_enviados': np.random.randint(100, 10000, 10),\n",
    "    'exito_conexion': [True, True, False, True, True, True, False, False, True, True]\n",
    "}\n",
    "# Creamos el DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(\"1. Explorando el DataFrame:\")\n",
    "print(df.head())\n",
    "print(\"\\nInformaci贸n del DataFrame:\")\n",
    "print(df.info())\n",
    "print(\"\\nEstad铆sticas descriptivas:\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Selecci贸n de Datos\n",
    "Seleccionamos columnas espec铆ficas del DataFrame para un an谩lisis m谩s detallado. Por ejemplo:\n",
    "print(df['protocolo'] para mostrar la columna protocolo o, m煤ltiples columnas como en en el segundo caso seleccinoamos la ip origen, protocolo y puerto. Tambi茅n se extraer la informaci贸n por 铆ndice, en este caso 2 filas solo con las columnas bajo indice 0 (timestamp) y 2 (ip_destino).\n",
    "Por 煤ltimo se extraen todas las filas cuyo protocolo sea HTTP, listando las columnas timestamp, ip_origen y puerto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Selecci贸n de datos:\n",
      "\n",
      "Selecci贸n de una columna (Serie):\n",
      "0     HTTP\n",
      "1    HTTPS\n",
      "2      SSH\n",
      "3      RDP\n",
      "4     HTTP\n",
      "5     HTTP\n",
      "6    HTTPS\n",
      "7      SSH\n",
      "8     HTTP\n",
      "9      RDP\n",
      "Name: protocolo, dtype: object\n",
      "\n",
      "Selecci贸n de m煤ltiples columnas (DataFrame):\n",
      "      ip_origen protocolo  puerto\n",
      "0   192.168.1.1      HTTP      80\n",
      "1   192.168.1.2     HTTPS     443\n",
      "2   192.168.1.3       SSH      22\n",
      "3   192.168.1.4       RDP    3389\n",
      "4   192.168.1.5      HTTP    8080\n",
      "5   192.168.1.6      HTTP      80\n",
      "6   192.168.1.7     HTTPS     443\n",
      "7   192.168.1.8       SSH      22\n",
      "8   192.168.1.9      HTTP    8080\n",
      "9  192.168.1.10       RDP    3389\n",
      "\n",
      "Selecci贸n por 铆ndice con iloc (primeras 2 filas, columnas 0 y 2):\n",
      "            timestamp ip_destino\n",
      "0 2023-01-01 00:00:00   10.0.0.1\n",
      "1 2023-01-01 01:00:00   10.0.0.2\n",
      "\n",
      "Selecci贸n por nombre con loc (filas donde protocolo es 'HTTP'):\n",
      "            timestamp    ip_origen  puerto\n",
      "0 2023-01-01 00:00:00  192.168.1.1      80\n",
      "4 2023-01-01 04:00:00  192.168.1.5    8080\n",
      "5 2023-01-01 05:00:00  192.168.1.6      80\n",
      "8 2023-01-01 08:00:00  192.168.1.9    8080\n"
     ]
    }
   ],
   "source": [
    "# 2. Selecci贸n de datos\n",
    "print(\"\\n2. Selecci贸n de datos:\")\n",
    "# Seleccionar una columna (devuelve una Serie)\n",
    "print(\"\\nSelecci贸n de una columna (Serie):\")\n",
    "print(df['protocolo'])\n",
    "# Seleccionar m煤ltiples columnas (devuelve un DataFrame)\n",
    "print(\"\\nSelecci贸n de m煤ltiples columnas (DataFrame):\")\n",
    "print(df[['ip_origen', 'protocolo', 'puerto']])\n",
    "# Selecci贸n por 铆ndice con iloc\n",
    "print(\"\\nSelecci贸n por 铆ndice con iloc (primeras 2 filas, columnas 0 y 2):\")\n",
    "print(df.iloc[0:2, [0, 2]])\n",
    "# Selecci贸n por nombre con loc\n",
    "print(\"\\nSelecci贸n por nombre con loc (filas donde protocolo es 'HTTP'):\")\n",
    "print(df.loc[df['protocolo'] == 'HTTP', ['timestamp', 'ip_origen', 'puerto']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filtrado de Datos\n",
    "Aplicamos distintos filtros a la informacion del DataFrame con el fin de extraer subconjuntos de datos relevantes, como conexiones exitosas o conexiones HTTP en el puerto 80. Para esto lo que hacemos es guardar en una variable \"conxiones_exitosas\" las filas de DataFrame cuya columna \"exito_conexion\" contenga el valor True, para listar luego las columnas timestamp, ip_orign y protocolo.\n",
    "En el segundo ejemplo, se hace un filtrado m煤ltiple en este caso por protocolo HTTP y puerto 80, pero en este caso se listan las 7 columnas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Filtrado de datos:\n",
      "\n",
      "Conexiones exitosas:\n",
      "            timestamp     ip_origen protocolo\n",
      "0 2023-01-01 00:00:00   192.168.1.1      HTTP\n",
      "1 2023-01-01 01:00:00   192.168.1.2     HTTPS\n",
      "3 2023-01-01 03:00:00   192.168.1.4       RDP\n",
      "4 2023-01-01 04:00:00   192.168.1.5      HTTP\n",
      "5 2023-01-01 05:00:00   192.168.1.6      HTTP\n",
      "8 2023-01-01 08:00:00   192.168.1.9      HTTP\n",
      "9 2023-01-01 09:00:00  192.168.1.10       RDP\n",
      "\n",
      "Conexiones HTTP en puerto 80:\n",
      "            timestamp    ip_origen ip_destino  puerto protocolo  \\\n",
      "0 2023-01-01 00:00:00  192.168.1.1   10.0.0.1      80      HTTP   \n",
      "5 2023-01-01 05:00:00  192.168.1.6   10.0.0.3      80      HTTP   \n",
      "\n",
      "   bytes_enviados  exito_conexion  \n",
      "0            2875            True  \n",
      "5            4901            True  \n"
     ]
    }
   ],
   "source": [
    "# 3. Filtrado de datos\n",
    "print(\"\\n3. Filtrado de datos:\")\n",
    "# Filtrar conexiones exitosas\n",
    "conexiones_exitosas = df[df['exito_conexion'] == True]\n",
    "print(\"\\nConexiones exitosas:\")\n",
    "print(conexiones_exitosas[['timestamp', 'ip_origen', 'protocolo']])\n",
    "# Filtrado m煤ltiple (conexiones HTTP en puerto 80)\n",
    "http_port80 = df[(df['protocolo'] == 'HTTP') & (df['puerto'] == 80)]\n",
    "print(\"\\nConexiones HTTP en puerto 80:\")\n",
    "print(http_port80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transformaci贸n de Datos\n",
    "A帽adimos nuevas columnas y aplicamos funciones para transformar los datos como protocolos HTTP/HTTPS en el tipo de protocolo WEB, o el SSH en el tipo ADMIN. Para esto al mismo DataFrame \"df\" que ya tenemos le agregamos la columna \"hora\", tomando de la columna \"timestamp\" solamente la hora (df['timestamp'].dt.hour).\n",
    "Posteriormente se usa la funci贸n apply para que a los registros de la columna protocolo que sean \"HTTP\" o \"HTTPS\" les cambie o coloque \"WEB\", esto mismo lo hace para el \"SSH\" que es un protocolo de administraci贸n y se le coloca como \"ADMIN\", para el resto de protocolos les coloca como \"OTRO\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Transformaci贸n de datos:\n",
      "\n",
      "DataFrame con nueva columna 'hora':\n",
      "            timestamp  hora protocolo\n",
      "0 2023-01-01 00:00:00     0      HTTP\n",
      "1 2023-01-01 01:00:00     1     HTTPS\n",
      "2 2023-01-01 02:00:00     2       SSH\n",
      "3 2023-01-01 03:00:00     3       RDP\n",
      "4 2023-01-01 04:00:00     4      HTTP\n",
      "5 2023-01-01 05:00:00     5      HTTP\n",
      "6 2023-01-01 06:00:00     6     HTTPS\n",
      "7 2023-01-01 07:00:00     7       SSH\n",
      "8 2023-01-01 08:00:00     8      HTTP\n",
      "9 2023-01-01 09:00:00     9       RDP\n",
      "\n",
      "DataFrame con clasificaci贸n de servicios:\n",
      "  protocolo tipo_servicio\n",
      "0      HTTP           WEB\n",
      "1     HTTPS           WEB\n",
      "2       SSH         ADMIN\n",
      "3       RDP          OTRO\n",
      "4      HTTP           WEB\n",
      "5      HTTP           WEB\n",
      "6     HTTPS           WEB\n",
      "7       SSH         ADMIN\n",
      "8      HTTP           WEB\n",
      "9       RDP          OTRO\n"
     ]
    }
   ],
   "source": [
    "# 4. Transformaci贸n de datos\n",
    "print(\"\\n4. Transformaci贸n de datos:\")\n",
    "# A帽adir una nueva columna\n",
    "df['hora'] = df['timestamp'].dt.hour\n",
    "print(\"\\nDataFrame con nueva columna 'hora':\")\n",
    "print(df[['timestamp', 'hora', 'protocolo']])\n",
    "# Aplicar una funci贸n con apply\n",
    "def clasificar_protocolo(protocolo):\n",
    "    if protocolo in ['HTTP', 'HTTPS']:\n",
    "        return 'WEB'\n",
    "    elif protocolo == 'SSH':\n",
    "        return 'ADMIN'\n",
    "    else:\n",
    "        return 'OTRO'\n",
    "df['tipo_servicio'] = df['protocolo'].apply(clasificar_protocolo)\n",
    "print(\"\\nDataFrame con clasificaci贸n de servicios:\")\n",
    "print(df[['protocolo', 'tipo_servicio']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agregaci贸n de Datos\n",
    "Agrupamos los datos por protocolo y se calculan estad铆sticas como el conteo de conexiones y estad铆sticas descriptivas de los bytes enviados.\n",
    "\n",
    "Para esto se esta utilizando la funci贸n groupby de pandas que realiza operaciones de agrupamiento y estad铆sticas sobre un DataFrame (df).\n",
    "- df.groupby('protocolo').- Agrupa por la columna protocolo, es decir, pandas agrupa todas las filas que tienen el mismo valor en la columna protocolo.\n",
    "- .size().- Cuenta cu谩ntas veces aparece cada valor 煤nico (HTTP, HTTPS, etc.)) en la columna protocolo.\n",
    "\n",
    "Luego para obtener las estad铆sticas dscriptivas, \n",
    "\n",
    "- ['bytes_enviados'].- Despu茅s de hacer el agrupamiento, selecciona la columna bytes_enviados para realizar las operaciones sobre esta columna. \n",
    "- .agg(['count', 'mean', 'min', 'max']).- Aplica varias funciones agregadas a la columna bytes_enviados, especificamente las siguientes:\n",
    "\n",
    "    * el n煤mero de valores no nulos (count)\n",
    "    * la media de los valores (mean)\n",
    "    * el valor m铆nimo (min)\n",
    "    * el valor m谩ximo (max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Agregaci贸n de datos:\n",
      "\n",
      "Conteo de conexiones por protocolo:\n",
      "protocolo\n",
      "HTTP     4\n",
      "HTTPS    2\n",
      "RDP      2\n",
      "SSH      2\n",
      "dtype: int64\n",
      "\n",
      "Estad铆sticas de bytes enviados por protocolo:\n",
      "           count     mean   min   max\n",
      "protocolo                            \n",
      "HTTP           4  5708.75  2875  8694\n",
      "HTTPS          2  1877.50   411  3344\n",
      "RDP            2  6749.00  5383  8115\n",
      "SSH            2  6159.00  3046  9272\n"
     ]
    }
   ],
   "source": [
    "# 5. Agregaci贸n de datos\n",
    "print(\"\\n5. Agregaci贸n de datos:\")\n",
    "# Agrupar por protocolo y contar conexiones\n",
    "conteo_por_protocolo = df.groupby('protocolo').size()\n",
    "print(\"\\nConteo de conexiones por protocolo:\")\n",
    "print(conteo_por_protocolo)\n",
    "# Estad铆sticas por protocolo\n",
    "stats_por_protocolo = df.groupby('protocolo')['bytes_enviados'].agg(['count', 'mean', 'min', 'max'])\n",
    "print(\"\\nEstad铆sticas de bytes enviados por protocolo:\")\n",
    "print(stats_por_protocolo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pivotado de Datos\n",
    "En este punto, se una tabla pivote o tabla dinamica para analizar los bytes enviados por tipo de servicio y 茅xito de conexi贸n.\n",
    "\n",
    "- pd.pivot_table(df).- Crea la tabla din谩mica a partir del DataFrame df y con las l铆neas:\n",
    "\n",
    "   * values='bytes_enviados'.- Indica que los valores que se usaran en la tabla din谩mica provienen de la columna \"bytes_enviados\" del DataFrame df.\n",
    "   * index='tipo_servicio'.- Define a la columna \"tipo_servicio\" como el 铆ndice de la tabla din谩mica. Esto significa que los valores 煤nicos de tipo_servicio se organizar谩n en las filas de la tabla resultante.\n",
    "   * columns='exito_conexion'.- Indica que la columna \"exito_conexion\" se utilizar谩 para crear las columnas de la tabla din谩mica.\n",
    "   * aggfunc='mean'.- Especifica la funci贸n agregada a usarse para combinar los datos dentro de las celdas de la tabla din谩mica. En este caso, se est谩 utilizando 'mean' qu茅,  c贸mo se explico antes, calcular谩 el promedio de los valores de \"bytes_enviados\" para cada combinaci贸n de tipo_servicio y exito_conexion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. Pivotado de datos:\n",
      "\n",
      "Tabla pivote de bytes enviados por tipo de servicio y 茅xito de conexi贸n:\n",
      "exito_conexion   False   True \n",
      "tipo_servicio                 \n",
      "ADMIN           6159.0     NaN\n",
      "OTRO               NaN  6749.0\n",
      "WEB              411.0  5235.8\n"
     ]
    }
   ],
   "source": [
    "# 6. Pivotado de datos\n",
    "print(\"\\n6. Pivotado de datos:\")\n",
    "# Tabla pivote de bytes enviados por tipo de servicio y protocolo\n",
    "pivot = pd.pivot_table(df, \n",
    "                      values='bytes_enviados', \n",
    "                      index='tipo_servicio', \n",
    "                      columns='exito_conexion', \n",
    "                      aggfunc='mean')\n",
    "print(\"\\nTabla pivote de bytes enviados por tipo de servicio y 茅xito de conexi贸n:\")\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Detecci贸n de Anomal铆as Simples\n",
    "Este c贸digo detecta posibles anomal铆as en el volumen de datos transferidos (bytes_enviados) mediante el uso del Z-score. Calculamos el Z-score para identificar valores at铆picos en los bytes enviados y detectamos posibles anomal铆as. Para este caso se consideran como anomal铆as los valores mayores a 1.5, el proceso consiste en:\n",
    "\n",
    "- Z-score.- Mide cu谩ntas desviaciones est谩ndar se encuentra un valor de la media. Es una forma est谩ndar de comparar valores con diferentes distribuciones.\n",
    "- df['bytes_enviados'].mean().- Se usa para calcular la media de la columna \"bytes_enviados\".\n",
    "- df['bytes_enviados'].std().- Se usa para calcular la desviaci贸n est谩ndar de la columna \"bytes_enviados\", mide cu谩nta dispersi贸n hay respecto a la media.\n",
    "\n",
    "Para el c谩lculo del Z-score, Z-score usa la f贸rmula para cada valor x en \"bytes_enviados\":\n",
    "\n",
    "$$ Z = \\frac{x - \\mu}{\\sigma} $$\n",
    "\n",
    " \n",
    "donde, en nuestro caso:\n",
    ": es el valor de bytes_enviados.\n",
    ": es la media de los bytes_enviados.\n",
    ": es la desviaci贸n est谩ndar de bytes_enviados.\n",
    "\n",
    "\n",
    "En la segunda parte, lo que se hace s:\n",
    "- abs(df['z_score']) > 1.5.- Aqu铆 se filtra el DataFrame para identificar los registros cuyo Z-score (desviaci贸n de la media) sea mayor que 1.5 o menor que -1.5.\n",
    "\n",
    "Al final se muestran los datos que en base a esta condici贸n resultan como anomalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. Detecci贸n de anomal铆as simples:\n",
      "\n",
      "Posibles conexiones an贸malas por volumen de datos transferidos:\n",
      "            timestamp    ip_origen protocolo  bytes_enviados   z_score\n",
      "6 2023-01-01 06:00:00  192.168.1.7     HTTPS             411 -1.671078\n"
     ]
    }
   ],
   "source": [
    "# 7. Detecci贸n de anomal铆as simples\n",
    "print(\"\\n7. Detecci贸n de anomal铆as simples:\")\n",
    "# Calcular el Z-score para identificar valores at铆picos en bytes_enviados\n",
    "df['z_score'] = (df['bytes_enviados'] - df['bytes_enviados'].mean()) / df['bytes_enviados'].std()\n",
    "anomalias = df[abs(df['z_score']) > 1.5]  # Consideramos como an贸malos Z-scores > 1.5\n",
    "print(\"\\nPosibles conexiones an贸malas por volumen de datos transferidos:\")\n",
    "print(anomalias[['timestamp', 'ip_origen', 'protocolo', 'bytes_enviados', 'z_score']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EjercicioPracticoClase3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
