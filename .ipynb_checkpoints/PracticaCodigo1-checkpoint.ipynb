{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamiento de Datos con Pandas, Numpy y Matplotlib\n",
    "## 1. Exploración del DataFrame\n",
    "Creamos un dataset simulando un registro de conexiones de red, este se lo almacena en un DataFrame. Exploramos las primeras filas, la información general del DataFrame y las estadísticas descriptivas.\n",
    "\n",
    "En este bloque primero importamos las librerías/dependencias (pandas, numpy, matplotlib) que utilizaremos para el ejercicio.\n",
    "Luego pasamos a crear el datset \"data\" e incluir la información que se llenara en éste, p. ej.: fecha y hora, las ip origen  destino, el puerto, protocolo, los bytes que se han enviado y si la conexión fue exitosa (true) o no (false).\n",
    "\n",
    "Una vez se ha llenado el dataset, usamos pandas para crear un DataFrame \"df\" a partir de este dataset.\n",
    "Luego mediante el uso de las bondades de pandas exploramos el DataFrame, vemos su información y estadísticas.\n",
    "- df.head().- Muestra las 5 primeras filas del Data Frame,  esto permite revisar los primeros datos en el DataFrame para verificar que se hayan cargado correctamente.\n",
    "- df.info().- Este comando muestra la información concisa del DataFrame, incluye: número de filas y columnas, nombres de las columnas, cantidad de valores nulos de cada columna, cuanta memoria usa el DataFrame,\n",
    "- df.describe().- Genera estadísticas descriptivas de las columnas numéricas del DataFrame, incluye información como: \n",
    "    * el número de valores no nulos (count),\n",
    "    * la media de los valores (mean)\n",
    "    * la desviación estándar (std),\n",
    "    * el valor mínimo (min),\n",
    "    * el primer cuartil (25%),\n",
    "    * la mediana (50%),\n",
    "    * el tercer cuartil (75%),\n",
    "    * y el valor máximo (max).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Explorando el DataFrame:\n",
      "            timestamp    ip_origen ip_destino  puerto protocolo  \\\n",
      "0 2023-01-01 00:00:00  192.168.1.1   10.0.0.1      80      HTTP   \n",
      "1 2023-01-01 01:00:00  192.168.1.2   10.0.0.2     443     HTTPS   \n",
      "2 2023-01-01 02:00:00  192.168.1.3   10.0.0.3      22       SSH   \n",
      "3 2023-01-01 03:00:00  192.168.1.4   10.0.0.1    3389       RDP   \n",
      "4 2023-01-01 04:00:00  192.168.1.5   10.0.0.2    8080      HTTP   \n",
      "\n",
      "   bytes_enviados  exito_conexion  \n",
      "0            2875            True  \n",
      "1            3344            True  \n",
      "2            9272           False  \n",
      "3            5383            True  \n",
      "4            6365            True  \n",
      "\n",
      "Información del DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   timestamp       10 non-null     datetime64[ns]\n",
      " 1   ip_origen       10 non-null     object        \n",
      " 2   ip_destino      10 non-null     object        \n",
      " 3   puerto          10 non-null     int64         \n",
      " 4   protocolo       10 non-null     object        \n",
      " 5   bytes_enviados  10 non-null     int64         \n",
      " 6   exito_conexion  10 non-null     bool          \n",
      "dtypes: bool(1), datetime64[ns](1), int64(2), object(3)\n",
      "memory usage: 622.0+ bytes\n",
      "None\n",
      "\n",
      "Estadísticas descriptivas:\n",
      "                 timestamp       puerto  bytes_enviados\n",
      "count                   10    10.000000       10.000000\n",
      "mean   2023-01-01 04:30:00  2402.800000     5240.600000\n",
      "min    2023-01-01 00:00:00    22.000000      411.000000\n",
      "25%    2023-01-01 02:15:00    80.000000     3120.500000\n",
      "50%    2023-01-01 04:30:00   443.000000     5142.000000\n",
      "75%    2023-01-01 06:45:00  3389.000000     7677.500000\n",
      "max    2023-01-01 09:00:00  8080.000000     9272.000000\n",
      "std                    NaN  3269.645404     2890.111001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6229/2243821585.py:6: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  'timestamp': pd.date_range(start='2023-01-01', periods=10, freq='H'),\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Creamos un dataset simulando un registro de conexiones de red\n",
    "data = {\n",
    "    'timestamp': pd.date_range(start='2023-01-01', periods=10, freq='H'),\n",
    "    'ip_origen': ['192.168.1.' + str(i) for i in range(1, 11)],\n",
    "    'ip_destino': ['10.0.0.' + str(i % 3 + 1) for i in range(10)],\n",
    "    'puerto': [80, 443, 22, 3389, 8080, 80, 443, 22, 8080, 3389],\n",
    "    'protocolo': ['HTTP', 'HTTPS', 'SSH', 'RDP', 'HTTP', 'HTTP', 'HTTPS', 'SSH', 'HTTP', 'RDP'],\n",
    "    'bytes_enviados': np.random.randint(100, 10000, 10),\n",
    "    'exito_conexion': [True, True, False, True, True, True, False, False, True, True]\n",
    "}\n",
    "# Creamos el DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(\"1. Explorando el DataFrame:\")\n",
    "print(df.head())\n",
    "print(\"\\nInformación del DataFrame:\")\n",
    "print(df.info())\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Selección de Datos\n",
    "Seleccionamos columnas específicas del DataFrame para un análisis más detallado. Por ejemplo:\n",
    "print(df['protocolo'] para mostrar la columna protocolo o, múltiples columnas como en en el segundo caso seleccinoamos la ip origen, protocolo y puerto. También se extraer la información por índice, en este caso 2 filas solo con las columnas bajo indice 0 (timestamp) y 2 (ip_destino).\n",
    "Por último se extraen todas las filas cuyo protocolo sea HTTP, listando las columnas timestamp, ip_origen y puerto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Selección de datos:\n",
      "\n",
      "Selección de una columna (Serie):\n",
      "0     HTTP\n",
      "1    HTTPS\n",
      "2      SSH\n",
      "3      RDP\n",
      "4     HTTP\n",
      "5     HTTP\n",
      "6    HTTPS\n",
      "7      SSH\n",
      "8     HTTP\n",
      "9      RDP\n",
      "Name: protocolo, dtype: object\n",
      "\n",
      "Selección de múltiples columnas (DataFrame):\n",
      "      ip_origen protocolo  puerto\n",
      "0   192.168.1.1      HTTP      80\n",
      "1   192.168.1.2     HTTPS     443\n",
      "2   192.168.1.3       SSH      22\n",
      "3   192.168.1.4       RDP    3389\n",
      "4   192.168.1.5      HTTP    8080\n",
      "5   192.168.1.6      HTTP      80\n",
      "6   192.168.1.7     HTTPS     443\n",
      "7   192.168.1.8       SSH      22\n",
      "8   192.168.1.9      HTTP    8080\n",
      "9  192.168.1.10       RDP    3389\n",
      "\n",
      "Selección por índice con iloc (primeras 2 filas, columnas 0 y 2):\n",
      "            timestamp ip_destino\n",
      "0 2023-01-01 00:00:00   10.0.0.1\n",
      "1 2023-01-01 01:00:00   10.0.0.2\n",
      "\n",
      "Selección por nombre con loc (filas donde protocolo es 'HTTP'):\n",
      "            timestamp    ip_origen  puerto\n",
      "0 2023-01-01 00:00:00  192.168.1.1      80\n",
      "4 2023-01-01 04:00:00  192.168.1.5    8080\n",
      "5 2023-01-01 05:00:00  192.168.1.6      80\n",
      "8 2023-01-01 08:00:00  192.168.1.9    8080\n"
     ]
    }
   ],
   "source": [
    "# 2. Selección de datos\n",
    "print(\"\\n2. Selección de datos:\")\n",
    "# Seleccionar una columna (devuelve una Serie)\n",
    "print(\"\\nSelección de una columna (Serie):\")\n",
    "print(df['protocolo'])\n",
    "# Seleccionar múltiples columnas (devuelve un DataFrame)\n",
    "print(\"\\nSelección de múltiples columnas (DataFrame):\")\n",
    "print(df[['ip_origen', 'protocolo', 'puerto']])\n",
    "# Selección por índice con iloc\n",
    "print(\"\\nSelección por índice con iloc (primeras 2 filas, columnas 0 y 2):\")\n",
    "print(df.iloc[0:2, [0, 2]])\n",
    "# Selección por nombre con loc\n",
    "print(\"\\nSelección por nombre con loc (filas donde protocolo es 'HTTP'):\")\n",
    "print(df.loc[df['protocolo'] == 'HTTP', ['timestamp', 'ip_origen', 'puerto']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filtrado de Datos\n",
    "Aplicamos distintos filtros a la informacion del DataFrame con el fin de extraer subconjuntos de datos relevantes, como conexiones exitosas o conexiones HTTP en el puerto 80. Para esto lo que hacemos es guardar en una variable \"conxiones_exitosas\" las filas de DataFrame cuya columna \"exito_conexion\" contenga el valor True, para listar luego las columnas timestamp, ip_orign y protocolo.\n",
    "En el segundo ejemplo, se hace un filtrado múltiple en este caso por protocolo HTTP y puerto 80, pero en este caso se listan las 7 columnas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Filtrado de datos:\n",
      "\n",
      "Conexiones exitosas:\n",
      "            timestamp     ip_origen protocolo\n",
      "0 2023-01-01 00:00:00   192.168.1.1      HTTP\n",
      "1 2023-01-01 01:00:00   192.168.1.2     HTTPS\n",
      "3 2023-01-01 03:00:00   192.168.1.4       RDP\n",
      "4 2023-01-01 04:00:00   192.168.1.5      HTTP\n",
      "5 2023-01-01 05:00:00   192.168.1.6      HTTP\n",
      "8 2023-01-01 08:00:00   192.168.1.9      HTTP\n",
      "9 2023-01-01 09:00:00  192.168.1.10       RDP\n",
      "\n",
      "Conexiones HTTP en puerto 80:\n",
      "            timestamp    ip_origen ip_destino  puerto protocolo  \\\n",
      "0 2023-01-01 00:00:00  192.168.1.1   10.0.0.1      80      HTTP   \n",
      "5 2023-01-01 05:00:00  192.168.1.6   10.0.0.3      80      HTTP   \n",
      "\n",
      "   bytes_enviados  exito_conexion  \n",
      "0            2875            True  \n",
      "5            4901            True  \n"
     ]
    }
   ],
   "source": [
    "# 3. Filtrado de datos\n",
    "print(\"\\n3. Filtrado de datos:\")\n",
    "# Filtrar conexiones exitosas\n",
    "conexiones_exitosas = df[df['exito_conexion'] == True]\n",
    "print(\"\\nConexiones exitosas:\")\n",
    "print(conexiones_exitosas[['timestamp', 'ip_origen', 'protocolo']])\n",
    "# Filtrado múltiple (conexiones HTTP en puerto 80)\n",
    "http_port80 = df[(df['protocolo'] == 'HTTP') & (df['puerto'] == 80)]\n",
    "print(\"\\nConexiones HTTP en puerto 80:\")\n",
    "print(http_port80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transformación de Datos\n",
    "Añadimos nuevas columnas y aplicamos funciones para transformar los datos como protocolos HTTP/HTTPS en el tipo de protocolo WEB, o el SSH en el tipo ADMIN. Para esto al mismo DataFrame \"df\" que ya tenemos le agregamos la columna \"hora\", tomando de la columna \"timestamp\" solamente la hora (df['timestamp'].dt.hour).\n",
    "Posteriormente se usa la función apply para que a los registros de la columna protocolo que sean \"HTTP\" o \"HTTPS\" les cambie o coloque \"WEB\", esto mismo lo hace para el \"SSH\" que es un protocolo de administración y se le coloca como \"ADMIN\", para el resto de protocolos les coloca como \"OTRO\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Transformación de datos:\n",
      "\n",
      "DataFrame con nueva columna 'hora':\n",
      "            timestamp  hora protocolo\n",
      "0 2023-01-01 00:00:00     0      HTTP\n",
      "1 2023-01-01 01:00:00     1     HTTPS\n",
      "2 2023-01-01 02:00:00     2       SSH\n",
      "3 2023-01-01 03:00:00     3       RDP\n",
      "4 2023-01-01 04:00:00     4      HTTP\n",
      "5 2023-01-01 05:00:00     5      HTTP\n",
      "6 2023-01-01 06:00:00     6     HTTPS\n",
      "7 2023-01-01 07:00:00     7       SSH\n",
      "8 2023-01-01 08:00:00     8      HTTP\n",
      "9 2023-01-01 09:00:00     9       RDP\n",
      "\n",
      "DataFrame con clasificación de servicios:\n",
      "  protocolo tipo_servicio\n",
      "0      HTTP           WEB\n",
      "1     HTTPS           WEB\n",
      "2       SSH         ADMIN\n",
      "3       RDP          OTRO\n",
      "4      HTTP           WEB\n",
      "5      HTTP           WEB\n",
      "6     HTTPS           WEB\n",
      "7       SSH         ADMIN\n",
      "8      HTTP           WEB\n",
      "9       RDP          OTRO\n"
     ]
    }
   ],
   "source": [
    "# 4. Transformación de datos\n",
    "print(\"\\n4. Transformación de datos:\")\n",
    "# Añadir una nueva columna\n",
    "df['hora'] = df['timestamp'].dt.hour\n",
    "print(\"\\nDataFrame con nueva columna 'hora':\")\n",
    "print(df[['timestamp', 'hora', 'protocolo']])\n",
    "# Aplicar una función con apply\n",
    "def clasificar_protocolo(protocolo):\n",
    "    if protocolo in ['HTTP', 'HTTPS']:\n",
    "        return 'WEB'\n",
    "    elif protocolo == 'SSH':\n",
    "        return 'ADMIN'\n",
    "    else:\n",
    "        return 'OTRO'\n",
    "df['tipo_servicio'] = df['protocolo'].apply(clasificar_protocolo)\n",
    "print(\"\\nDataFrame con clasificación de servicios:\")\n",
    "print(df[['protocolo', 'tipo_servicio']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agregación de Datos\n",
    "Agrupamos los datos por protocolo y se calculan estadísticas como el conteo de conexiones y estadísticas descriptivas de los bytes enviados.\n",
    "\n",
    "Para esto se esta utilizando la función groupby de pandas que realiza operaciones de agrupamiento y estadísticas sobre un DataFrame (df).\n",
    "- df.groupby('protocolo').- Agrupa por la columna protocolo, es decir, pandas agrupa todas las filas que tienen el mismo valor en la columna protocolo.\n",
    "- .size().- Cuenta cuántas veces aparece cada valor único (HTTP, HTTPS, etc.)) en la columna protocolo.\n",
    "\n",
    "Luego para obtener las estadísticas dscriptivas, \n",
    "\n",
    "- ['bytes_enviados'].- Después de hacer el agrupamiento, selecciona la columna bytes_enviados para realizar las operaciones sobre esta columna. \n",
    "- .agg(['count', 'mean', 'min', 'max']).- Aplica varias funciones agregadas a la columna bytes_enviados, especificamente las siguientes:\n",
    "\n",
    "    * el número de valores no nulos (count)\n",
    "    * la media de los valores (mean)\n",
    "    * el valor mínimo (min)\n",
    "    * el valor máximo (max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Agregación de datos:\n",
      "\n",
      "Conteo de conexiones por protocolo:\n",
      "protocolo\n",
      "HTTP     4\n",
      "HTTPS    2\n",
      "RDP      2\n",
      "SSH      2\n",
      "dtype: int64\n",
      "\n",
      "Estadísticas de bytes enviados por protocolo:\n",
      "           count     mean   min   max\n",
      "protocolo                            \n",
      "HTTP           4  5708.75  2875  8694\n",
      "HTTPS          2  1877.50   411  3344\n",
      "RDP            2  6749.00  5383  8115\n",
      "SSH            2  6159.00  3046  9272\n"
     ]
    }
   ],
   "source": [
    "# 5. Agregación de datos\n",
    "print(\"\\n5. Agregación de datos:\")\n",
    "# Agrupar por protocolo y contar conexiones\n",
    "conteo_por_protocolo = df.groupby('protocolo').size()\n",
    "print(\"\\nConteo de conexiones por protocolo:\")\n",
    "print(conteo_por_protocolo)\n",
    "# Estadísticas por protocolo\n",
    "stats_por_protocolo = df.groupby('protocolo')['bytes_enviados'].agg(['count', 'mean', 'min', 'max'])\n",
    "print(\"\\nEstadísticas de bytes enviados por protocolo:\")\n",
    "print(stats_por_protocolo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pivotado de Datos\n",
    "En este punto, se una tabla pivote o tabla dinamica para analizar los bytes enviados por tipo de servicio y éxito de conexión.\n",
    "\n",
    "- pd.pivot_table(df).- Crea la tabla dinámica a partir del DataFrame df y con las líneas:\n",
    "\n",
    "   * values='bytes_enviados'.- Indica que los valores que se usaran en la tabla dinámica provienen de la columna \"bytes_enviados\" del DataFrame df.\n",
    "   * index='tipo_servicio'.- Define a la columna \"tipo_servicio\" como el índice de la tabla dinámica. Esto significa que los valores únicos de tipo_servicio se organizarán en las filas de la tabla resultante.\n",
    "   * columns='exito_conexion'.- Indica que la columna \"exito_conexion\" se utilizará para crear las columnas de la tabla dinámica.\n",
    "   * aggfunc='mean'.- Especifica la función agregada a usarse para combinar los datos dentro de las celdas de la tabla dinámica. En este caso, se está utilizando 'mean' qué,  cómo se explico antes, calculará el promedio de los valores de \"bytes_enviados\" para cada combinación de tipo_servicio y exito_conexion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. Pivotado de datos:\n",
      "\n",
      "Tabla pivote de bytes enviados por tipo de servicio y éxito de conexión:\n",
      "exito_conexion   False   True \n",
      "tipo_servicio                 \n",
      "ADMIN           6159.0     NaN\n",
      "OTRO               NaN  6749.0\n",
      "WEB              411.0  5235.8\n"
     ]
    }
   ],
   "source": [
    "# 6. Pivotado de datos\n",
    "print(\"\\n6. Pivotado de datos:\")\n",
    "# Tabla pivote de bytes enviados por tipo de servicio y protocolo\n",
    "pivot = pd.pivot_table(df, \n",
    "                      values='bytes_enviados', \n",
    "                      index='tipo_servicio', \n",
    "                      columns='exito_conexion', \n",
    "                      aggfunc='mean')\n",
    "print(\"\\nTabla pivote de bytes enviados por tipo de servicio y éxito de conexión:\")\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Detección de Anomalías Simples\n",
    "Este código detecta posibles anomalías en el volumen de datos transferidos (bytes_enviados) mediante el uso del Z-score. Calculamos el Z-score para identificar valores atípicos en los bytes enviados y detectamos posibles anomalías. Para este caso se consideran como anomalías los valores mayores a 1.5, el proceso consiste en:\n",
    "\n",
    "- Z-score.- Mide cuántas desviaciones estándar se encuentra un valor de la media. Es una forma estándar de comparar valores con diferentes distribuciones.\n",
    "- df['bytes_enviados'].mean().- Se usa para calcular la media de la columna \"bytes_enviados\".\n",
    "- df['bytes_enviados'].std().- Se usa para calcular la desviación estándar de la columna \"bytes_enviados\", mide cuánta dispersión hay respecto a la media.\n",
    "\n",
    "Para el cálculo del Z-score, Z-score usa la fórmula para cada valor x en \"bytes_enviados\":\n",
    "​\n",
    "$$ Z = \\frac{x - \\mu}{\\sigma} $$\n",
    "\n",
    " \n",
    "donde, en nuestro caso:\n",
    "𝑥: es el valor de bytes_enviados.\n",
    "𝜇: es la media de los bytes_enviados.\n",
    "𝜎: es la desviación estándar de bytes_enviados.\n",
    "\n",
    "\n",
    "En la segunda parte, lo que se hace s:\n",
    "- abs(df['z_score']) > 1.5.- Aquí se filtra el DataFrame para identificar los registros cuyo Z-score (desviación de la media) sea mayor que 1.5 o menor que -1.5.\n",
    "\n",
    "Al final se muestran los datos que en base a esta condición resultan como anomalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. Detección de anomalías simples:\n",
      "\n",
      "Posibles conexiones anómalas por volumen de datos transferidos:\n",
      "            timestamp    ip_origen protocolo  bytes_enviados   z_score\n",
      "6 2023-01-01 06:00:00  192.168.1.7     HTTPS             411 -1.671078\n"
     ]
    }
   ],
   "source": [
    "# 7. Detección de anomalías simples\n",
    "print(\"\\n7. Detección de anomalías simples:\")\n",
    "# Calcular el Z-score para identificar valores atípicos en bytes_enviados\n",
    "df['z_score'] = (df['bytes_enviados'] - df['bytes_enviados'].mean()) / df['bytes_enviados'].std()\n",
    "anomalias = df[abs(df['z_score']) > 1.5]  # Consideramos como anómalos Z-scores > 1.5\n",
    "print(\"\\nPosibles conexiones anómalas por volumen de datos transferidos:\")\n",
    "print(anomalias[['timestamp', 'ip_origen', 'protocolo', 'bytes_enviados', 'z_score']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EjercicioPracticoClase3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
